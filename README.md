# **Nuxt 3 Full-Stack with Redis and MongoDB**

This project is a full-stack application using **Nuxt 3** for the frontend, **Redis** for caching, and **MongoDB** as the primary database. It implements **infinite scrolling pagination**, **upload functionality**, and an optimized caching strategy for performance.

## **ğŸ“‚ Project Structure**

```text
ğŸ“¦ project-root
â”œâ”€â”€ docker-compose.yml       # Docker setup for frontend, MongoDB, and Redis
â”œâ”€â”€ frontend/                # Nuxt 3 Frontend
â”‚   â”œâ”€â”€ components/          # Vue components (ImageCard, ImageList, Tabs, etc.)
â”‚   â”œâ”€â”€ composables/         # Reusable composables (useImages.ts)
â”‚   â”œâ”€â”€ pages/               # Nuxt pages
â”‚   â”œâ”€â”€ server/api/          # Backend API (generate.ts, images.ts, etc.)
â”‚   â”œâ”€â”€ server/utils/        # MongoDB and Redis utilities
â”‚   â”œâ”€â”€ nuxt.config.ts       # Nuxt configuration
â”‚   â”œâ”€â”€ dockerfile           # Docker configuration for frontend
â”‚   â”œâ”€â”€ package.json         # Dependencies
â”‚   â””â”€â”€ tsconfig.json        # TypeScript configuration
```

## **ğŸš€ How to Use**

![alt text](image.png)

### **1ï¸âƒ£ Setup & Run the Project**

```sh
# Clone the repository
git clone <repo_url>
cd project-root

# Install dependencies
npm install

# Start MongoDB, Redis, and Frontend via Docker
docker-compose up -d

# Start Nuxt 3 in development mode
npm run dev
```

### **2ï¸âƒ£ Upload an Image**

- Use the **Upload Button** on the frontend to upload images.
- Uploaded images are **stored in MongoDB** and **cached in Redis** if applicable.

### **3ï¸âƒ£ Fetch Images with Infinite Scrolling**

- **Active Users (`active=true`)** use **Redis cache**.
- **Non-Active Users (`active=false`)** **always** fetch from MongoDB.
- Pagination loads **50 images per request**.

### **4ï¸âƒ£ Generate Heavy Data** (For Performance Testing)

```sh
curl -X POST "http://localhost:3000/api/generate-heavy"
```

- Generates **a large dataset** in MongoDB for testing.

## **âš¡ Cache Strategy & Mechanism (Page & Active)**

### **1ï¸âƒ£ Active Users (`active=true`)**

âœ… **Cached in Redis** (No expiration) for faster response times
âœ… **Prefetches `n-1` and `n+1` pages**.
âœ… **If cache is stale, fetch from MongoDB and update Redis**.

### **2ï¸âƒ£ Non-Active Users (`active=false`)**

âŒ **Not cached in Redis**.

âŒ **Every request fetches from MongoDB**.

âŒ **Slower but ensures fresh data for testing performance.**

### **3ï¸âƒ£ Cache Expiration & Management**

ğŸ•’ **Redis entries for `active=true` do not expire automatically**.

ğŸ•’ **Redis cache is cleared when heavy data is generated**.

ğŸ•’ **Manual refresh is possible via `?refresh=true` in API calls**.

## **ğŸ“Œ API Endpoints**

| **Endpoint**                     | **Method** | **Description** |
|----------------------------------|-----------|----------------|
| `/api/generate`                  | `POST`    | Resets images and generates 200 new images (100 ActiveUser + 100 NonActiveUser) |
| `/api/images?page=1&active=true` | `GET`     | Fetches images with pagination. Uses Redis cache for active users. |
| `/api/generate-heavy`            | `POST`    | Generates 100,000 images in MongoDB and clears Redis cache. |

### **1ï¸âƒ£ Rest Images and Generate**

```sh
POST /api/generate
```

**Response:**

```json
{
  "images": [{"_id": "abc123", "url": "/uploads/image1.png"}],
  "message": "âœ… Generated 200 images (100 ActiveUser + 100 NonActiveUser)"
}
```

### **2ï¸âƒ£ Fetch Images (With Cache for Active Users)**

```sh
GET /api/images?page=1&active=true
```

**Query Params:**

- `page` â†’ Page number (e.g., `1, 2, 3...`)
- `active` â†’ Whether the user is active (`true` = Cached, `false` = No Cache)
- `refresh` â†’ If `true`, forces cache refresh.

**Response:**

```json
{
  "status": "cache",
  "statusMessage": "Loaded from Redis cache",
  "images": [{"_id": "abc123", "url": "/uploads/image1.png"}]
}
```

### **3ï¸âƒ£ Generate Large Dataset**

```sh
POST /api/generate-heavy
```

- Generates **100,000 images** in MongoDB.
- Clears Redis cache to ensure fresh dataset is used.

**Response:**

```json
{
  "status": "success",
  "statusMessage": "âœ… Generated 100,000 images and cleared cache"
}
```

## **ğŸš€ Final Thoughts**

This project optimizes **performance with Redis caching**, supports **infinite scrolling pagination**, and **efficiently fetches & generates images** in MongoDB.

ğŸ¯ **Next Steps:**

- Implement **unit tests (Cypress, Jest)** to benchmark caching vs. non-caching.
- Add **bulk image upload support**.
- Improve **Redis eviction strategies** to keep memory usage optimized
